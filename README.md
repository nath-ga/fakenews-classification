# Fake News Klassifikation mit DistilBERT

Dieses Projekt demonstriert, wie man mit Hilfe eines feinjustierten BERT-Modells (DistilBERT) automatisch zwischen echten und gefÃ¤lschten Nachrichten unterscheidet. Ziel ist es, ein Machine-Learning-Modell zu entwickeln, das gesellschaftlich relevante Fake News erkennt.

## ProjektÃ¼berblick

- **Modell:** DistilBERT (transformers)
- **Trainingsdaten:** [Kaggle Fake News Dataset (Rahul Thorat)](https://www.kaggle.com/datasets/ioanacheres/disinformation-dataset)
- **Ziel:** Textklassifikation â†’ `0 = real`, `1 = fake`
- **Sprache:** Englisch
- **Anwendungsfall:** Erkennung von Fake News aus News-Artikeln

## Implementierung

- Analyse des Datensatzes (`prepare_data.py`)
- Datenvorverarbeitung (`prepare_data.py`)
- Modelltraining (`train_model.py`)
- Evaluation & Visualisierung (`eval_visualize_metrics.py`)
- Ausgabe von Beispielvorhersagen inkl. Konfidenzwerten (`predict_examples.py`)

## Ergebnisse

- **Test-Genauigkeit:** ca. 91 %
- **Klassifikationsbericht:**  
  Precision, Recall und F1-Score fÃ¼r beide Klassen (siehe Confusion Matrix)
- **Beispielvorhersagen mit Konfidenzwerten:**  
  Zeigt sichere und unsichere Klassifikationen

## ðŸ“¦ Ordnerstruktur

```
fakenews-classification/
â”‚
â”œâ”€â”€ data/                     # DatensÃ¤tze
â”‚   â””â”€â”€ fakenews.csv
â”‚
â”œâ”€â”€ outputs/                  # Modell, Grafiken, Ergebnisse
â”‚   â””â”€â”€ model_final/
â”‚   â””â”€â”€ figures/
â”‚
â”œâ”€â”€ src/                      # Quellcode
â”‚   â”œâ”€â”€ eda.py
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ eval_visualize_metrics.py
â”‚   â””â”€â”€ predict_examples.py
â”‚
â””â”€â”€ README.md                 # Dieses Dokument
```

## Anforderungen

pip install transformers datasets torch scikit-learn matplotlib pandas
Getestet unter Python 3.12, ohne GPU

## Modell

distilbert-base-uncased
2 Epochen, Lernrate 5e-5
80/20 Train/Test-Split

